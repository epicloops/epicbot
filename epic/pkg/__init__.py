# -*- coding: utf-8 -*-
'''
Downloads, packages, and uploads the results of epicbot and epicsampler.
'''
import os
import shutil
import logging
import zipfile

from epic import config
from epic.cache import Cache
from epic.db import session_maker
from epic.db.models import DeclarativeBase, Tracks
import epic.qry
from epic import s3


log = logging.getLogger(__name__)


ECHONEST_KEYS = [
    'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B',
]

ECHONEST_MODES = ['Major', 'Minor']


def _write(fname, data):
    path = os.path.dirname(fname)
    if not os.path.exists(path):
        os.makedirs(path)

    with open(fname, 'w') as f:
        f.write('\n'.join(data))

    return fname

def _write_license(path, track):
    license_txt = [
        'ARTIST: {}'.format(track.artist),
        'ARTIST URL: {}'.format(track.artist_page_url),
        'TRACK TITLE: {}'.format(track.title),
        'TRACK URL: {}'.format(track.track_page_url),
        'LICENSE URL: {}'.format(track.license_url),
    ]
    return _write(os.path.join(path, 'LICENSE.txt'), license_txt)

def _write_profile(path, track):
    profile_txt = [
        'TEMPO: {} BPM'.format(track.echonest_tempo),

        'TEMPO CONFIDENCE: {}'.format(track.echonest_tempo_confidence),

        'KEY: {}'.format(ECHONEST_KEYS[track.echonest_key]),

        'KEY CONFIDENCE: {} BPM'.format(track.echonest_key_confidence),

        'MODE: {}'.format(ECHONEST_MODES[track.echonest_mode]),

        'MODE CONFIDENCE: {} BPM'.format(track.echonest_mode_confidence),

        'TIME SIGNATURE: {} beats/measure'.format(
                                                track.echonest_time_signature),

        'TIME SIGNATURE CONFIDENCE: {}'.format(
                                    track.echonest_time_signature_confidence),
    ]
    return _write(os.path.join(path, 'PROFILE.txt'), profile_txt)

def _write_manifest(path, sample_type, samples):
    manifest = []
    if sample_type == 'sections':
        for sample in samples:

            entry = [
                '{:04d}.mp3'.format(sample.sample_num),

                '  - SECTION CONFIDENCE: {}'.format(sample.confidence),

                '  - TEMPO: {} BPM'.format(sample.tempo),

                '  - TEMPO CONFIDENCE: {}'.format(sample.tempo_confidence),

                '  - KEY: {}'.format(ECHONEST_KEYS[sample.key]),

                '  - KEY CONFIDENCE: {}'.format(sample.key_confidence),

                '  - MODE: {}'.format(ECHONEST_MODES[sample.mode]),

                '  - MODE CONFIDENCE: {}'.format(sample.mode_confidence),

                '  - TIME SIGNATURE: {} beats/measure'.format(
                                                        sample.time_signature),

                '  - TIME SIGNATURE CONFIDENCE: {}'.format(
                                            sample.time_signature_confidence),
            ]

            manifest += entry
    else:
        manifest += ['FILENAME: CONFIDENCE']
        for sample in samples:
            manifest.append('{0:04d}.mp3: {1}'.format(sample.sample_num,
                                                      sample.confidence))

    return _write(os.path.join(path, sample_type, '0000_MANIFEST.txt'),
                  manifest)

def download(crawl_start, spider, sampler_start, qry, limit, dl_samples=True,
             *args, **kwargs):
    '''Download tracks and samples generated by epicbot and epicsampler.

    :param crawl_start: Start timestamp from epicbot crawl to process.
    :param spider: Epicbot spider to process.
    :param sampler_start: Start timestamp from epicsampler run to process.
    :param qry: Qry used to identify best tracks to download.
    :param limit: Number of tracks to download.
    :param dl_samples: Flag to prevent samples from being downloaded.
    '''
    sampler_cache = Cache('sampler')
    if sampler_cache.read():
        sampler_cache.purge()
    sampler_cache.write(crawl_start)

    track_ids = getattr(epic.qry, qry)(crawl_start, limit, output=False)

    dl_dir = os.path.join(os.getcwd(), 'dl')

    if os.path.exists(dl_dir):
        shutil.rmtree(dl_dir)
        log.info('Removed %s', dl_dir)
    os.makedirs(dl_dir)
    log.info('Created %s', dl_dir)

    # download tracks
    bot_dir = '/'.join(['bot', crawl_start, spider])
    for k in s3.list(bot_dir):
        track_id = k.name.split('/')[3]
        if track_id not in track_ids:
            continue
        dest = os.path.join(dl_dir, track_id, k.name)
        s3.get(k, dest)

    # download samples
    if dl_samples:
        sampler_dir = '/'.join(['sampler', crawl_start, spider, sampler_start])
        for k in s3.list(sampler_dir):
            track_id = k.name.split('/')[4]
            if track_id not in track_ids:
                continue
            dest = os.path.join(dl_dir, track_id, k.name.split('/')[5], k.name)
            s3.get(k, dest)

def build(*args, **kwargs):
    '''Build contents of pkg directory to be zipped and uploaded.

    Copy downloaded files to pkg dir. Generate license, profile, and manifest
    files.
    '''
    dl_dir = os.path.join(os.getcwd(), 'dl')
    if not os.path.exists(dl_dir):
        log.info('No dl dir found.')
        return

    sampler_cache = Cache('sampler')
    crawl_start = sampler_cache.read()

    pkg_dir = os.path.join(os.getcwd(), 'pkg')

    if os.path.exists(pkg_dir):
        shutil.rmtree(pkg_dir)
        log.info('Removed: %s', pkg_dir)
    shutil.copytree(dl_dir, pkg_dir)
    log.info('Copied: %s to %s', dl_dir, pkg_dir)

    Session = session_maker()

    track_ids = os.listdir(dl_dir)
    for i, track_id in enumerate(track_ids):
        track_dir = os.path.join(pkg_dir, track_id)

        session = Session()
        track = session.query(Tracks).\
                    filter(Tracks.track_id == track_id,
                           Tracks.crawl_start == crawl_start).one()

        fname = _write_license(track_dir, track)
        log.info('Created: %s', fname)
        fname = _write_profile(track_dir, track)
        log.info('Created: %s', fname)

        sample_dirs = set(os.listdir(track_dir)).intersection(
                                                set(config.PROCESS_SAMPLES))
        for sample_type in sample_dirs:
            table = DeclarativeBase.metadata.tables[sample_type]
            samples = session.query(table).\
                            filter(table.c.track_id == track_id,
                                   table.c.crawl_start == crawl_start)
            fname = _write_manifest(track_dir, str(table), samples)
            log.info('Created: %s', fname)

        # rename track_dir from hash to friendlier number
        dest = os.path.join(pkg_dir, '{:02d}'.format(i))
        os.rename(track_dir, dest)
        log.info('Renamed: %s to %s', track_dir, dest)

def zip_(zip_name, *args, **kwargs):
    '''Zip the contents of the pkg directory.'''
    pkg_dir = os.path.join(os.getcwd(), 'pkg')
    if not os.path.exists(pkg_dir):
        log.info('No pkg dir found.')
        return

    zip_name = '{}.zip'.format(zip_name)
    zipf = zipfile.ZipFile(zip_name, 'w')
    for root, _, files in os.walk(pkg_dir):
        for f in files:
            fname = os.path.join(root, f)
            rel_fname = os.path.relpath(fname, pkg_dir)
            zipf.write(fname, rel_fname)
            log.info('Zipped: %s as %s', fname, rel_fname)
    zipf.close()
    return zip_name

def upload(zip_name, clean=True, *args, **kwargs):
    '''Upload zip to s3.

    :param zip_name: Zip file to upload.
    :param clean: Flag to remove pkg dir after uplaod.
    '''
    s3.set('pkg/{}'.format(zip_name), zip_name)
    sampler_cache = Cache('sampler')
    sampler_cache.purge()
    if clean:
        for d in ('dl', 'pkg'):
            shutil.rmtree(d)
            log.info('Removed: %s', d)
        os.remove(zip_name)


def pkg(crawl_start, spider, sampler_start, qry, limit, zip_name, clean=True,
        *args, **kwargs):
    '''A convenience function to download, build, zip, and upload all at once.

    :param dl_dir: Directory, relative to cwd, containing tracks and samples.
    :param pkg_bucket: s3 bucket where zip will be uploaded.
    :param crawl_start: Start timestamp from epicbot crawl to process.
    :param clean: Flag to remove pkg dir after uplaod.
    '''
    download(crawl_start, spider, sampler_start, qry, limit, *args, **kwargs)
    build(*args, **kwargs)
    zip_name = zip_(zip_name, *args, **kwargs)
    upload(zip_name, clean, *args, **kwargs)
